{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Variational Autoencoder and Latent Diffusion Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from train import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import variational_autoencoder as vae\n",
    "import latent_diffusion\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cache exists, loading from cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vae_mlp\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " autoencoder_input (InputLayer)  [(None, 128, 128, 3  0          []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " encoder (Functional)           [(None, 1024),       46304576    ['autoencoder_input[0][0]']      \n",
      "                                 (None, 1024)]                                                    \n",
      "                                                                                                  \n",
      " z (Lambda)                     (None, 1024)         0           ['encoder[0][0]',                \n",
      "                                                                  'encoder[0][1]']                \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, 128, 128, 3)  15219587    ['z[0][0]']                      \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 1024)        0           ['encoder[0][1]']                \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.math.square_1 (TFOpLambda)  (None, 1024)         0           ['encoder[0][0]']                \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)      (None,)              0           ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None,)              0           ['autoencoder_input[0][0]']      \n",
      "                                                                                                  \n",
      " tf.math.subtract_2 (TFOpLambda  (None, 1024)        0           ['tf.__operators__.add_2[0][0]', \n",
      " )                                                                'tf.math.square_1[0][0]']       \n",
      "                                                                                                  \n",
      " tf.math.exp_1 (TFOpLambda)     (None, 1024)         0           ['encoder[0][1]']                \n",
      "                                                                                                  \n",
      " tf.convert_to_tensor_1 (TFOpLa  (None,)             0           ['tf.reshape_3[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)         (None,)              0           ['tf.reshape_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.subtract_3 (TFOpLambda  (None, 1024)        0           ['tf.math.subtract_2[0][0]',     \n",
      " )                                                                'tf.math.exp_1[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.squared_difference_1 (  (None,)             0           ['tf.convert_to_tensor_1[0][0]', \n",
      " TFOpLambda)                                                      'tf.cast_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum_1 (TFOpLamb  (None,)             0           ['tf.math.subtract_3[0][0]']     \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  ()                  0           ['tf.math.squared_difference_1[0]\n",
      " bda)                                                            [0]']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLambda  (None,)             0           ['tf.math.reduce_sum_1[0][0]']   \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLambda  ()                  0           ['tf.math.reduce_mean_2[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLambda  (None,)             0           ['tf.math.multiply_4[0][0]']     \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None,)             0           ['tf.math.multiply_3[0][0]',     \n",
      " mbda)                                                            'tf.math.multiply_5[0][0]']     \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  ()                  0           ['tf.__operators__.add_3[0][0]'] \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " add_loss_1 (AddLoss)           ()                   0           ['tf.math.reduce_mean_3[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 61,524,163\n",
      "Trainable params: 61,524,163\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "417/417 [==============================] - 127s 305ms/step\n"
     ]
    }
   ],
   "source": [
    "# Variational Autoencoder\n",
    "with open(\"/Users/lucky/GitHub/PokeGenerator/model/training_config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "images = load_dataset(config)\n",
    "\n",
    "latest_model_file = \"/Users/lucky/GitHub/PokeGenerator/model/checkpoints/model_2024-03-18-22-44-30.keras\"\n",
    "variational_autoencoder = tf.keras.models.load_model(latest_model_file)\n",
    "variational_autoencoder.summary()\n",
    "\n",
    "encoder = variational_autoencoder.get_layer('encoder')\n",
    "decoder = variational_autoencoder.get_layer('decoder')\n",
    "\n",
    "reconstructions = variational_autoencoder.predict(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_vectors(v1, v2, num_steps=10):\n",
    "    \"\"\"Interpolates between two vectors with a specified number of steps.\"\"\"\n",
    "    ratios = np.linspace(0, 1, num_steps)\n",
    "    interpolated_vectors = [(1 - ratio) * v1 + ratio * v2 for ratio in ratios]\n",
    "    return np.array(interpolated_vectors)\n",
    "\n",
    "def get_interpolated_images(decoder, latent_vectors, index1, index2, num_steps=10):\n",
    "    \"\"\"Gets a series of images showing the transition between two points.\"\"\"\n",
    "    latent_vector_1 = latent_vectors[index1]  # Use specific indices\n",
    "    latent_vector_2 = latent_vectors[index2]\n",
    "\n",
    "    # Interpolate between the two latent vectors\n",
    "    interpolated_vectors = interpolate_vectors(latent_vector_1, latent_vector_2, num_steps=num_steps)\n",
    "\n",
    "    # Decode the interpolated latent vectors into images\n",
    "    decoded_images = decoder.predict(interpolated_vectors)\n",
    "\n",
    "    return decoded_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 15s 37ms/step\n",
      "1/1 [==============================] - 0s 101ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5a27ded4fb4af78f2605fb93bc5172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Page', max=1, min=1), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact, IntSlider\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def interactive_image_gallery(images, images_per_page=10, figsize_per_image=(1, 1)):\n",
    "    \"\"\"Creates an interactive gallery for navigating through images.\"\"\"\n",
    "    total_images = len(images)\n",
    "    max_pages = (total_images + images_per_page - 1) // images_per_page\n",
    "\n",
    "    def show_images(page=1):\n",
    "        start = (page - 1) * images_per_page\n",
    "        end = start + images_per_page\n",
    "        page_images = images[start:end]\n",
    "\n",
    "        # Determine the number of columns and rows to display\n",
    "        cols = images_per_page  # Display all images on one row\n",
    "        rows = 1\n",
    "        fig_width = figsize_per_image[0] * cols  # Total width of figure\n",
    "        fig_height = figsize_per_image[1] * rows  # Total height of figure\n",
    "        plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "        for i, image in enumerate(page_images):\n",
    "            plt.subplot(rows, cols, i + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    interact(show_images, page=IntSlider(min=1, max=max_pages, step=1, value=1, description='Page'))\n",
    "\n",
    "# Example usage:\n",
    "# Get the interpolated images\n",
    "z_mean, z_log_var = encoder.predict(images)\n",
    "interpolated_images = get_interpolated_images(decoder, z_mean, index1=6, index2=20, num_steps=10)\n",
    "\n",
    "# Display the images in an interactive gallery\n",
    "interactive_image_gallery(interpolated_images, images_per_page=10, figsize_per_image=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations of Originals and Reconstructions VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "def display_image_pairs(originals, reconstructions, page=1, pairs_per_page=4):\n",
    "    \"\"\"Displays original and reconstructed image pairs in a gallery format.\"\"\"\n",
    "    # Calculate which images to show on this page\n",
    "    start = (page - 1) * pairs_per_page\n",
    "    end = start + pairs_per_page\n",
    "    page_originals = originals[start:end]\n",
    "    page_reconstructions = reconstructions[start:end]\n",
    "    \n",
    "    # Setup the figure based on the number of image pairs to display\n",
    "    cols = 4 # We need 2 columns for each pair\n",
    "    rows = pairs_per_page  # The number of rows is the same as pairs per page\n",
    "    plt.figure(figsize=(2.5 * cols, 2.5 * rows))\n",
    "    \n",
    "    # Display each pair of original and reconstructed images\n",
    "    for i in range(pairs_per_page):\n",
    "        if i < len(page_originals):\n",
    "            # Display original image\n",
    "            plt.subplot(rows, cols, 2*i + 1)\n",
    "            plt.imshow(page_originals[i], cmap='gray')\n",
    "            plt.title('Original')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Display reconstructed image\n",
    "            plt.subplot(rows, cols, 2*i + 2)\n",
    "            plt.imshow(page_reconstructions[i], cmap='gray')\n",
    "            plt.title('Reconstructed')\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def interactive_gallery(originals, reconstructions, pairs_per_page=4):\n",
    "    \"\"\"Creates an interactive gallery for navigating through image pairs.\"\"\"\n",
    "    total_pairs = len(originals)\n",
    "    max_pages = (total_pairs + pairs_per_page - 1) // pairs_per_page\n",
    "    \n",
    "    interact(lambda page: display_image_pairs(originals, reconstructions, page, pairs_per_page),\n",
    "             page=IntSlider(min=1, max=max_pages, step=1, value=1, description='Page'))\n",
    "\n",
    "interactive_gallery(images, reconstructions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Diffusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 12s 28ms/step\n",
      "Sampled latent vectors shape: (13334, 512)\n",
      "Latent Space Dimension: 512\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"reverse_process_mlp_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 1, 512)       512000      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 512)]        0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 512)          0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 1024)         0           ['input_1[0][0]',                \n",
      "                                                                  'flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          524800      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          262656      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          262656      ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 512)          262656      ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,824,768\n",
      "Trainable params: 1,824,768\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "745e751f84a24fee88d98e044619f397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 19s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "# Latent Diffusion\n",
    "latent_vectors = encoder.predict(images)\n",
    "z_mean, z_log_var = latent_vectors\n",
    "\n",
    "sampled_latent_vectors = vae.sampling(latent_vectors)\n",
    "\n",
    "# Ensure the shape is what your model expects\n",
    "print(\"Sampled latent vectors shape:\", sampled_latent_vectors.shape) \n",
    "# Demonison of Latent Space\n",
    "print(\"Latent Space Dimension:\", sampled_latent_vectors.shape[1])\n",
    "\n",
    "# # Training\n",
    "T = 1000\n",
    "betas = np.linspace(1e-4, .02, T)\n",
    "sigmas = np.sqrt(betas)\n",
    "alphas = 1 - betas\n",
    "alphas_cumprod = np.cumprod(alphas, axis=-1)\n",
    "\n",
    "ld_model = tf.keras.models.load_model(\"/Users/lucky/GitHub/PokeGenerator/model/checkpoints/latent_model_2024-03-19-17:41:00.keras\")\n",
    "ld_model.summary()\n",
    "\n",
    "# Generate sampled latent vectors\n",
    "sampled_latent_vectors = latent_diffusion.sample(\n",
    "    model=ld_model, \n",
    "    num_samples=sampled_latent_vectors.shape[0], \n",
    "    latent_dim=sampled_latent_vectors.shape[1], \n",
    "    T=T, \n",
    "    sigmas=sigmas, \n",
    "    alphas=alphas, \n",
    "    alphas_cumprod=alphas_cumprod\n",
    ")\n",
    "\n",
    "# Decode the sampled latent vectors to images\n",
    "decoded_images = decoder.predict(sampled_latent_vectors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Diffusion Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32793feef8324acebf3314f2e3a9031d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='Page', max=1667, min=1), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "def display_images(images, page=1, images_per_page=8):\n",
    "    \"\"\"Displays a page of images in a grid format.\"\"\"\n",
    "    start = (page - 1) * images_per_page\n",
    "    end = start + images_per_page\n",
    "    page_images = images[start:end]\n",
    "\n",
    "    cols = 4  # You can change this to how many columns you want to display\n",
    "    rows = (len(page_images) + cols - 1) // cols\n",
    "    fig_width = cols * 3  # 3 inches per image column\n",
    "    fig_height = rows * 3  # 3 inches per image row\n",
    "    plt.figure(figsize=(fig_width, fig_height))\n",
    "\n",
    "    for i, image in enumerate(page_images):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def interactive_image_gallery(images, images_per_page=8):\n",
    "    \"\"\"Creates an interactive gallery for navigating through images.\"\"\"\n",
    "    total_images = len(images)\n",
    "    max_pages = (total_images + images_per_page - 1) // images_per_page\n",
    "\n",
    "    interact(lambda page: display_images(images, page, images_per_page),\n",
    "             page=IntSlider(min=1, max=max_pages, step=1, value=1, description='Page'))\n",
    "\n",
    "# Call the interactive gallery with your decoded images\n",
    "interactive_image_gallery(decoded_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pokemon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
